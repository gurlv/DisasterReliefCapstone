{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning for Disaster Response Message Classification\n",
        "\n",
        "**Project Goal:** Build a multi-label classifier to categorize emergency messages during disasters\n",
        "\n",
        "**Dataset:** https://www.kaggle.com/datasets/landlord/multilingual-disaster-response-messages\n",
        "\n",
        "**This notebook includes:**\n",
        "1. Additional model optimization strategies to try to improve model performance\n",
        "\n",
        "\n",
        "### Note: Baseline model will already include the following optimization techniques:\n",
        "- Per-label class weighting via scale_pos_weight\n",
        "- Tuned hyperparameters from grid search"
      ],
      "metadata": {
        "id": "mftj-RziH5Lc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-n0oJL-HxL1",
        "outputId": "48a0e219-a7de-474a-a5b7-e00334fa2cea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Setup complete!\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import json\n",
        "import re\n",
        "import warnings\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    classification_report, f1_score, precision_score,\n",
        "    recall_score, hamming_loss, accuracy_score\n",
        ")\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"Setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load saved models and preprocessor\n",
        "# ============================================================\n",
        "model_dir = '/content/drive/MyDrive/AAI_Capstone/Models'\n",
        "data_dir = '/content/drive/MyDrive/AAI_Capstone/Datasets'\n",
        "\n",
        "# Load the trained XGBoost models\n",
        "print(\"Loading saved models...\")\n",
        "label_models = joblib.load(f'{model_dir}/optimized_xgboost_multilabel.pkl')\n",
        "print(f\"Loaded {len(label_models)} label-specific models\")\n",
        "\n",
        "# Load the full preprocessor (ColumnTransformer)\n",
        "print(\"Loading preprocessor...\")\n",
        "preprocessor = joblib.load(f'{model_dir}/preprocessor.pkl')\n",
        "print(\"Preprocessor loaded!\")\n",
        "\n",
        "# Load best hyperparameters\n",
        "with open(f'{model_dir}/best_hyperparameters.json', 'r') as f:\n",
        "    best_params = json.load(f)\n",
        "print(f\"Best params from previous training: {best_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OlRH_yaJMgU",
        "outputId": "3099f3a7-b256-4532-8aad-08cd49402d1e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading saved models...\n",
            "Loaded 34 label-specific models\n",
            "Loading preprocessor...\n",
            "Preprocessor loaded!\n",
            "Best params from previous training: {'max_depth': 8, 'learning_rate': 0.2, 'n_estimators': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "print(\"Loading datasets...\")\n",
        "df_train = pd.read_csv(f'{data_dir}/disaster_response_messages_training.csv')\n",
        "df_val = pd.read_csv(f'{data_dir}/disaster_response_messages_validation.csv')\n",
        "df_test = pd.read_csv(f'{data_dir}/disaster_response_messages_test.csv')\n",
        "\n",
        "print(f\"Train: {len(df_train)}, Val: {len(df_val)}, Test: {len(df_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIuwKBtzM4yP",
        "outputId": "46e497f2-0727-4a2e-a4c6-e4bb829f9884"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading datasets...\n",
            "Train: 21046, Val: 2573, Test: 2629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text preprocessing functions (make sure to match original)\n",
        "\n",
        "# Initialize NLTK components\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
        "    # Remove special characters and numbers (keep only letters and spaces)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if pd.isna(text) or text == \"\":\n",
        "        return \"\"\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stopwords and lemmatize, keep words with length > 2\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens\n",
        "              if token not in stop_words and len(token) > 2]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "print(\"Preprocessing functions defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF5hxp_XM9F_",
        "outputId": "446adbb6-cf13-4cda-f9e8-96a2515ff024"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing functions defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply text preprocessing to create 'cleaned_message'\n",
        "# ============================================================\n",
        "print(\"Cleaning and preprocessing text...\")\n",
        "\n",
        "# Apply cleaning\n",
        "print(\"  Cleaning text...\")\n",
        "df_train['cleaned_message'] = df_train['message'].apply(clean_text).apply(preprocess_text)\n",
        "df_val['cleaned_message'] = df_val['message'].apply(clean_text).apply(preprocess_text)\n",
        "df_test['cleaned_message'] = df_test['message'].apply(clean_text).apply(preprocess_text)\n",
        "\n",
        "print(\"Text preprocessing complete!\")\n",
        "print(f\"\\nSample cleaned messages:\")\n",
        "print(df_val[['message', 'cleaned_message']].head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IQyGuMoNIB1",
        "outputId": "e0f5e243-5d4d-4b00-e86c-632f0f251258"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning and preprocessing text...\n",
            "  Cleaning text...\n",
            "Text preprocessing complete!\n",
            "\n",
            "Sample cleaned messages:\n",
            "                                             message  \\\n",
            "0                    Looking for someone but no name   \n",
            "1  I am in Croix-des-Bouquets. We have health iss...   \n",
            "2  are you going to call me or do you want me to ...   \n",
            "\n",
            "                                     cleaned_message  \n",
            "0                               looking someone name  \n",
            "1  croixdesbouquets health issue worker santo are...  \n",
            "2                      going call want call let know  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare features and labels\n",
        "\n",
        "# Define label columns (exclude non-label columns)\n",
        "exclude_cols = ['id', 'message', 'original', 'genre', 'split', 'cleaned_message',\n",
        "                'message_length', 'word_count', 'avg_word_length', 'cleaned_word_count',\n",
        "                'exclamation_count', 'question_count', 'period_count', 'comma_count',\n",
        "                'has_urls', 'has_numbers', 'has_email', 'caps_ratio', 'genre_encoded']\n",
        "label_cols = [col for col in df_train.columns if col not in exclude_cols]\n",
        "\n",
        "# Identify and remove single-class labels (same as original notebook)\n",
        "y_train_full = df_train[label_cols]\n",
        "one_class_labels = y_train_full.columns[\n",
        "    (y_train_full.sum(axis=0) == 0) |\n",
        "    (y_train_full.sum(axis=0) == len(y_train_full))\n",
        "]\n",
        "print(f\"Removing {len(one_class_labels)} single-class labels: {list(one_class_labels)}\")\n",
        "\n",
        "filtered_label_cols = [col for col in label_cols if col not in one_class_labels]\n",
        "\n",
        "# Prepare features (preprocessor expects 'cleaned_message' and 'genre')\n",
        "X_train = df_train[['cleaned_message', 'genre']]\n",
        "X_val = df_val[['cleaned_message', 'genre']]\n",
        "X_test = df_test[['cleaned_message', 'genre']]\n",
        "\n",
        "# Prepare labels\n",
        "y_train = df_train[filtered_label_cols]\n",
        "y_val = df_val[filtered_label_cols]\n",
        "y_test = df_test[filtered_label_cols]\n",
        "\n",
        "print(f\"\\nFeature shapes: X_train={X_train.shape}, X_val={X_val.shape}, X_test={X_test.shape}\")\n",
        "print(f\"Label shapes: y_train={y_train.shape}, y_val={y_val.shape}, y_test={y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a57eXS7HNM3N",
        "outputId": "f05b44f6-b0c2-46e7-ac04-7ebd223b0967"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 3 single-class labels: ['PII', 'offer', 'child_alone']\n",
            "\n",
            "Feature shapes: X_train=(21046, 2), X_val=(2573, 2), X_test=(2629, 2)\n",
            "Label shapes: y_train=(21046, 34), y_val=(2573, 34), y_test=(2629, 34)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform features using loaded preprocessor\n",
        "print(\"Transforming features using loaded preprocessor...\")\n",
        "\n",
        "X_train_processed = preprocessor.transform(X_train)\n",
        "X_val_processed = preprocessor.transform(X_val)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "print(f\"\\nProcessed feature shapes:\")\n",
        "print(f\"  X_train_processed: {X_train_processed.shape}\")  # Should be (21027, 5003)\n",
        "print(f\"  X_val_processed:   {X_val_processed.shape}\")    # Should be (2571, 5003)\n",
        "print(f\"  X_test_processed:  {X_test_processed.shape}\")   # Should be (2618, 5003)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm5volHmNZZA",
        "outputId": "98ab8ac0-ad1e-488a-c2e3-c59e33874f26"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transforming features using loaded preprocessor...\n",
            "\n",
            "Processed feature shapes:\n",
            "  X_train_processed: (21046, 5003)\n",
            "  X_val_processed:   (2573, 5003)\n",
            "  X_test_processed:  (2629, 5003)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify loaded models work (Baseline Performance)\n",
        "print(\"Generating predictions with loaded models...\")\n",
        "\n",
        "# Check which labels are in both the models and validation set\n",
        "model_labels = set(label_models.keys())\n",
        "val_labels = set(y_val.columns)\n",
        "common_labels = sorted(list(model_labels.intersection(val_labels)))\n",
        "\n",
        "print(f\"Labels in saved models: {len(model_labels)}\")\n",
        "print(f\"Labels in validation set: {len(val_labels)}\")\n",
        "print(f\"Common labels: {len(common_labels)}\")\n",
        "\n",
        "# Only predict for labels that exist in both\n",
        "y_val_pred = pd.DataFrame(index=y_val.index, columns=common_labels)\n",
        "\n",
        "for label in common_labels:\n",
        "    clf = label_models[label]\n",
        "    y_val_pred[label] = clf.predict(X_val_processed)\n",
        "\n",
        "# Filter y_val to only include common labels IN THE SAME ORDER\n",
        "y_val_common = y_val[common_labels].copy()\n",
        "\n",
        "# FIX: Convert any value > 1 to 1 (binarize the labels)\n",
        "# This handles the 'related' column which has values [0, 1, 2]\n",
        "y_val_common = y_val_common.clip(upper=1)\n",
        "\n",
        "# Convert both to numpy arrays with same dtype\n",
        "y_true = y_val_common.values.astype(int)\n",
        "y_pred = y_val_pred.values.astype(int)\n",
        "\n",
        "# Verify the fix worked\n",
        "print(f\"\\nUnique values in y_true (after fix): {np.unique(y_true)}\")\n",
        "print(f\"Unique values in y_pred: {np.unique(y_pred)}\")\n",
        "\n",
        "# Calculate baseline metrics using numpy arrays\n",
        "baseline_f1_micro = f1_score(y_true, y_pred, average='micro', zero_division=0)\n",
        "baseline_f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "baseline_recall_micro = recall_score(y_true, y_pred, average='micro', zero_division=0)\n",
        "baseline_precision_micro = precision_score(y_true, y_pred, average='micro', zero_division=0)\n",
        "\n",
        "\n",
        "print(f\"BASELINE PERFORMANCE (Loaded XGBoost Models)\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"  F1 Micro:        {baseline_f1_micro:.4f}\")\n",
        "print(f\"  F1 Macro:        {baseline_f1_macro:.4f}\")\n",
        "print(f\"  Precision Micro: {baseline_precision_micro:.4f}\")\n",
        "print(f\"  Recall Micro:    {baseline_recall_micro:.4f}\")\n",
        "\n",
        "\n",
        "print(f\"\\nUsing {len(common_labels)} labels for optimization\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUkuVENlNn4M",
        "outputId": "1c1adce7-46b1-4381-b23f-8e97856b50bd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating predictions with loaded models...\n",
            "Labels in saved models: 34\n",
            "Labels in validation set: 34\n",
            "Common labels: 34\n",
            "\n",
            "Unique values in y_true (after fix): [0 1]\n",
            "Unique values in y_pred: [0 1]\n",
            "BASELINE PERFORMANCE (Loaded XGBoost Models)\n",
            "============================================================\n",
            "  F1 Micro:        0.6246\n",
            "  F1 Macro:        0.4614\n",
            "  Precision Micro: 0.5822\n",
            "  Recall Micro:    0.6737\n",
            "\n",
            "Using 34 labels for optimization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimization Strategy #1 - Threshold Tuning\n",
        "print(\"Finding optimal thresholds per label...\")\n",
        "\n",
        "# Get probability predictions for common labels only\n",
        "y_val_proba = pd.DataFrame(index=y_val.index, columns=common_labels, dtype=float)\n",
        "\n",
        "for label in common_labels:\n",
        "    clf = label_models[label]\n",
        "    y_val_proba[label] = clf.predict_proba(X_val_processed)[:, 1]\n",
        "\n",
        "# Find optimal threshold for each label\n",
        "optimal_thresholds = {}\n",
        "threshold_range = np.arange(0.1, 0.9, 0.05)\n",
        "\n",
        "for label in common_labels:\n",
        "    best_f1 = 0\n",
        "    best_threshold = 0.5\n",
        "\n",
        "    y_true_label = y_val_common[label].clip(upper=1).values  # Apply same fix\n",
        "\n",
        "    for threshold in threshold_range:\n",
        "        preds = (y_val_proba[label] > threshold).astype(int)\n",
        "        f1 = f1_score(y_true_label, preds, zero_division=0)\n",
        "\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = threshold\n",
        "\n",
        "    optimal_thresholds[label] = {'threshold': best_threshold, 'f1': best_f1}\n",
        "\n",
        "# Apply optimal thresholds\n",
        "y_val_pred_tuned = pd.DataFrame(index=y_val.index, columns=common_labels)\n",
        "for label in common_labels:\n",
        "    threshold = optimal_thresholds[label]['threshold']\n",
        "    y_val_pred_tuned[label] = (y_val_proba[label] > threshold).astype(int)\n",
        "\n",
        "# Prepare y_true with the fix applied\n",
        "y_true_tuned = y_val_common.clip(upper=1).values.astype(int)\n",
        "y_pred_tuned = y_val_pred_tuned.values.astype(int)\n",
        "\n",
        "# Evaluate\n",
        "tuned_f1_micro = f1_score(y_true_tuned, y_pred_tuned, average='micro', zero_division=0)\n",
        "tuned_f1_macro = f1_score(y_true_tuned, y_pred_tuned, average='macro', zero_division=0)\n",
        "tuned_recall_micro = recall_score(y_true_tuned, y_pred_tuned, average='micro', zero_division=0)\n",
        "tuned_precision_micro = precision_score(y_true_tuned, y_pred_tuned, average='micro', zero_division=0)\n",
        "\n",
        "\n",
        "print(f\"THRESHOLD-TUNED PERFORMANCE\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"  F1 Micro:        {tuned_f1_micro:.4f} (was {baseline_f1_micro:.4f}, diff: {tuned_f1_micro - baseline_f1_micro:+.4f})\")\n",
        "print(f\"  F1 Macro:        {tuned_f1_macro:.4f} (was {baseline_f1_macro:.4f}, diff: {tuned_f1_macro - baseline_f1_macro:+.4f})\")\n",
        "print(f\"  Precision Micro: {tuned_precision_micro:.4f} (was {baseline_precision_micro:.4f})\")\n",
        "print(f\"  Recall Micro:    {tuned_recall_micro:.4f} (was {baseline_recall_micro:.4f})\")\n",
        "\n",
        "\n",
        "# Show critical category thresholds\n",
        "critical_categories = ['medical_help', 'search_and_rescue', 'water', 'food', 'shelter']\n",
        "print(f\"\\nOptimal thresholds for critical categories:\")\n",
        "for cat in critical_categories:\n",
        "    if cat in optimal_thresholds:\n",
        "        print(f\"  {cat:20s}: {optimal_thresholds[cat]['threshold']:.2f} (F1: {optimal_thresholds[cat]['f1']:.3f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rHe3t_JO37P",
        "outputId": "acd57ff8-8130-4b97-a64f-b591a48a12e5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finding optimal thresholds per label...\n",
            "THRESHOLD-TUNED PERFORMANCE\n",
            "============================================================\n",
            "  F1 Micro:        0.6817 (was 0.6246, diff: +0.0571)\n",
            "  F1 Macro:        0.4986 (was 0.4614, diff: +0.0372)\n",
            "  Precision Micro: 0.6571 (was 0.5822)\n",
            "  Recall Micro:    0.7082 (was 0.6737)\n",
            "\n",
            "Optimal thresholds for critical categories:\n",
            "  medical_help        : 0.50 (F1: 0.505)\n",
            "  search_and_rescue   : 0.75 (F1: 0.365)\n",
            "  water               : 0.75 (F1: 0.701)\n",
            "  food                : 0.60 (F1: 0.779)\n",
            "  shelter             : 0.80 (F1: 0.675)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save optimal thresholds\n",
        "import json\n",
        "\n",
        "thresholds_save_path = f'{model_dir}/optimal_thresholds.json'\n",
        "with open(thresholds_save_path, 'w') as f:\n",
        "    json.dump(optimal_thresholds, f, indent=4)\n",
        "print(f\"Saved optimal thresholds to: {thresholds_save_path}\")\n",
        "\n",
        "# Display all thresholds sorted by value\n",
        "print(f\"\\nAll optimal thresholds (sorted by threshold value):\")\n",
        "for label, data in sorted(optimal_thresholds.items(), key=lambda x: x[1]['threshold']):\n",
        "    default_marker = \"\" if data['threshold'] != 0.5 else \" (default)\"\n",
        "    print(f\"  {label:25s}: {data['threshold']:.2f} (F1: {data['f1']:.3f}){default_marker}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mIoBWSXP3-V",
        "outputId": "93ceabdb-b4bf-4c53-afd0-42ce85b061f4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved optimal thresholds to: /content/drive/MyDrive/AAI_Capstone/Models/optimal_thresholds.json\n",
            "\n",
            "All optimal thresholds (sorted by threshold value):\n",
            "  related                  : 0.20 (F1: 0.879)\n",
            "  tools                    : 0.40 (F1: 0.118)\n",
            "  aid_related              : 0.45 (F1: 0.728)\n",
            "  medical_help             : 0.50 (F1: 0.505)\n",
            "  other_aid                : 0.50 (F1: 0.400)\n",
            "  weather_related          : 0.50 (F1: 0.785)\n",
            "  direct_report            : 0.55 (F1: 0.594)\n",
            "  hospitals                : 0.55 (F1: 0.333)\n",
            "  storm                    : 0.55 (F1: 0.768)\n",
            "  earthquake               : 0.60 (F1: 0.842)\n",
            "  food                     : 0.60 (F1: 0.779)\n",
            "  infrastructure_related   : 0.60 (F1: 0.325)\n",
            "  other_infrastructure     : 0.60 (F1: 0.232)\n",
            "  buildings                : 0.65 (F1: 0.533)\n",
            "  clothing                 : 0.65 (F1: 0.621)\n",
            "  fire                     : 0.65 (F1: 0.407)\n",
            "  request                  : 0.65 (F1: 0.684)\n",
            "  security                 : 0.65 (F1: 0.243)\n",
            "  shops                    : 0.65 (F1: 0.105)\n",
            "  floods                   : 0.70 (F1: 0.636)\n",
            "  medical_products         : 0.70 (F1: 0.500)\n",
            "  money                    : 0.70 (F1: 0.393)\n",
            "  other_weather            : 0.70 (F1: 0.335)\n",
            "  refugees                 : 0.70 (F1: 0.410)\n",
            "  cold                     : 0.75 (F1: 0.537)\n",
            "  death                    : 0.75 (F1: 0.626)\n",
            "  military                 : 0.75 (F1: 0.554)\n",
            "  missing_people           : 0.75 (F1: 0.250)\n",
            "  search_and_rescue        : 0.75 (F1: 0.365)\n",
            "  transport                : 0.75 (F1: 0.391)\n",
            "  water                    : 0.75 (F1: 0.701)\n",
            "  aid_centers              : 0.80 (F1: 0.254)\n",
            "  electricity              : 0.80 (F1: 0.444)\n",
            "  shelter                  : 0.80 (F1: 0.675)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Optimization Strategy #2 - Recall-Focused Thresholds for Critical Categories\n",
        "\n",
        "# For disaster response, missing a true positive (e.g., missing a medical_help request)\n",
        "# is worse than a false positive. Goal is to find thresholds that maximize recall\n",
        "# while keeping precision above a minimum threshold.\n",
        "\n",
        "print(\"Finding recall-optimized thresholds for critical categories...\")\n",
        "print(\"(Targeting minimum 70% recall while maximizing F1)\\n\")\n",
        "\n",
        "recall_optimized_thresholds = {}\n",
        "min_recall_target = 0.70\n",
        "\n",
        "for cat in critical_categories:\n",
        "    if cat not in common_labels:\n",
        "        continue\n",
        "\n",
        "    y_true_cat = y_val_common[cat].clip(upper=1).values\n",
        "    y_proba_cat = y_val_proba[cat].values\n",
        "\n",
        "    best_f1 = 0\n",
        "    best_threshold = 0.5\n",
        "    best_recall = 0\n",
        "    best_precision = 0\n",
        "\n",
        "    # Search from low to high thresholds\n",
        "    for threshold in np.arange(0.05, 0.9, 0.05):\n",
        "        preds = (y_proba_cat > threshold).astype(int)\n",
        "\n",
        "        recall = recall_score(y_true_cat, preds, zero_division=0)\n",
        "        precision = precision_score(y_true_cat, preds, zero_division=0)\n",
        "        f1 = f1_score(y_true_cat, preds, zero_division=0)\n",
        "\n",
        "        # Only consider thresholds that meet minimum recall\n",
        "        if recall >= min_recall_target and f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = threshold\n",
        "            best_recall = recall\n",
        "            best_precision = precision\n",
        "\n",
        "    # If no threshold meets recall target, use lowest threshold tested\n",
        "    if best_f1 == 0:\n",
        "        best_threshold = 0.05\n",
        "        preds = (y_proba_cat > best_threshold).astype(int)\n",
        "        best_recall = recall_score(y_true_cat, preds, zero_division=0)\n",
        "        best_precision = precision_score(y_true_cat, preds, zero_division=0)\n",
        "        best_f1 = f1_score(y_true_cat, preds, zero_division=0)\n",
        "\n",
        "    recall_optimized_thresholds[cat] = {\n",
        "        'threshold': best_threshold,\n",
        "        'f1': best_f1,\n",
        "        'recall': best_recall,\n",
        "        'precision': best_precision\n",
        "    }\n",
        "\n",
        "    # Compare with F1-optimized threshold\n",
        "    f1_thresh = optimal_thresholds[cat]['threshold']\n",
        "    print(f\"{cat}:\")\n",
        "    print(f\"  F1-optimized:     threshold={f1_thresh:.2f}, F1={optimal_thresholds[cat]['f1']:.3f}\")\n",
        "    print(f\"  Recall-optimized: threshold={best_threshold:.2f}, F1={best_f1:.3f}, Recall={best_recall:.3f}, Precision={best_precision:.3f}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMmI8PqFQE_v",
        "outputId": "7c1e457b-7609-4e61-9a75-89a7bed1d9c4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finding recall-optimized thresholds for critical categories...\n",
            "(Targeting minimum 70% recall while maximizing F1)\n",
            "\n",
            "medical_help:\n",
            "  F1-optimized:     threshold=0.50, F1=0.505\n",
            "  Recall-optimized: threshold=0.35, F1=0.437, Recall=0.714, Precision=0.315\n",
            "\n",
            "search_and_rescue:\n",
            "  F1-optimized:     threshold=0.75, F1=0.365\n",
            "  Recall-optimized: threshold=0.20, F1=0.091, Recall=0.753, Precision=0.048\n",
            "\n",
            "water:\n",
            "  F1-optimized:     threshold=0.75, F1=0.701\n",
            "  Recall-optimized: threshold=0.75, F1=0.701, Recall=0.739, Precision=0.667\n",
            "\n",
            "food:\n",
            "  F1-optimized:     threshold=0.60, F1=0.779\n",
            "  Recall-optimized: threshold=0.60, F1=0.779, Recall=0.793, Precision=0.765\n",
            "\n",
            "shelter:\n",
            "  F1-optimized:     threshold=0.80, F1=0.675\n",
            "  Recall-optimized: threshold=0.55, F1=0.629, Recall=0.720, Precision=0.559\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimization Strategy #3 - Expanded Hyperparameter Search\n",
        "# Retrain models for critical categories with expanded hyperparameter grid\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import time\n",
        "\n",
        "print(\"Expanded hyperparameter search for critical categories...\")\n",
        "\n",
        "# Expanded parameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.1, 0.2, 0.3],\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'min_child_weight': [1, 3, 5],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
        "}\n",
        "\n",
        "# For time efficiency, using a smaller grid first\n",
        "small_param_grid = {\n",
        "    'max_depth': [4, 5, 6],\n",
        "    'learning_rate': [0.15, 0.2, 0.25],\n",
        "    'n_estimators': [150, 200, 250],\n",
        "    'min_child_weight': [1, 3],\n",
        "    'subsample': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Preparing training data with same fix\n",
        "y_train_common = y_train[common_labels].copy().clip(upper=1)\n",
        "\n",
        "improved_models = {}\n",
        "improvement_results = []\n",
        "\n",
        "for cat in critical_categories:\n",
        "    if cat not in common_labels:\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nOptimizing {cat}...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    y_train_cat = y_train_common[cat].values\n",
        "    y_val_cat = y_val_common[cat].clip(upper=1).values\n",
        "\n",
        "    # Calculate class weight\n",
        "    n_pos = y_train_cat.sum()\n",
        "    n_neg = len(y_train_cat) - n_pos\n",
        "    scale_weight = n_neg / n_pos if n_pos > 0 else 1.0\n",
        "\n",
        "    # Current best score\n",
        "    current_f1 = optimal_thresholds[cat]['f1']\n",
        "\n",
        "    best_f1 = current_f1\n",
        "    best_params = None\n",
        "    best_model = None\n",
        "\n",
        "    # Grid search\n",
        "    param_list = list(ParameterGrid(small_param_grid))\n",
        "    print(f\"  Testing {len(param_list)} parameter combinations...\")\n",
        "\n",
        "    for i, params in enumerate(param_list):\n",
        "        if (i + 1) % 20 == 0:\n",
        "            print(f\"  Progress: {i+1}/{len(param_list)}\")\n",
        "\n",
        "        clf = XGBClassifier(\n",
        "            **params,\n",
        "            scale_pos_weight=scale_weight,\n",
        "            tree_method='hist',\n",
        "            device='cpu',\n",
        "            n_jobs=-1,\n",
        "            random_state=42,\n",
        "            verbosity=0\n",
        "        )\n",
        "\n",
        "        clf.fit(X_train_processed, y_train_cat)\n",
        "        y_pred_cat = clf.predict(X_val_processed)\n",
        "        f1 = f1_score(y_val_cat, y_pred_cat, zero_division=0)\n",
        "\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_params = params\n",
        "            best_model = clf\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    improvement = best_f1 - current_f1\n",
        "\n",
        "    improvement_results.append({\n",
        "        'category': cat,\n",
        "        'original_f1': current_f1,\n",
        "        'new_f1': best_f1,\n",
        "        'improvement': improvement,\n",
        "        'best_params': best_params\n",
        "    })\n",
        "\n",
        "    if best_model is not None:\n",
        "        improved_models[cat] = best_model\n",
        "        print(f\"  IMPROVED: F1 {current_f1:.3f} -> {best_f1:.3f} (+{improvement:.3f})\")\n",
        "        print(f\"  Best params: {best_params}\")\n",
        "    else:\n",
        "        print(f\"  No improvement found (current F1: {current_f1:.3f})\")\n",
        "\n",
        "    print(f\"  Time: {elapsed:.1f}s\")\n",
        "\n",
        "# Summary\n",
        "print(\"HYPERPARAMETER OPTIMIZATION SUMMARY\")\n",
        "for result in improvement_results:\n",
        "    status = \"IMPROVED\" if result['improvement'] > 0 else \"No change\"\n",
        "    print(f\"  {result['category']:20s}: {result['original_f1']:.3f} -> {result['new_f1']:.3f} ({status})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBRxnlfMQfwI",
        "outputId": "7663957c-a189-4b30-ba93-63b02979c23f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expanded hyperparameter search for critical categories...\n",
            "\n",
            "Optimizing medical_help...\n",
            "  Testing 108 parameter combinations...\n",
            "  Progress: 20/108\n",
            "  Progress: 40/108\n",
            "  Progress: 60/108\n",
            "  Progress: 80/108\n",
            "  Progress: 100/108\n",
            "  IMPROVED: F1 0.505 -> 0.513 (+0.008)\n",
            "  Best params: {'learning_rate': 0.15, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1.0}\n",
            "  Time: 2497.2s\n",
            "\n",
            "Optimizing search_and_rescue...\n",
            "  Testing 108 parameter combinations...\n",
            "  Progress: 20/108\n",
            "  Progress: 40/108\n",
            "  Progress: 60/108\n",
            "  Progress: 80/108\n",
            "  Progress: 100/108\n",
            "  No improvement found (current F1: 0.365)\n",
            "  Time: 2331.1s\n",
            "\n",
            "Optimizing water...\n",
            "  Testing 108 parameter combinations...\n",
            "  Progress: 20/108\n",
            "  Progress: 40/108\n",
            "  Progress: 60/108\n",
            "  Progress: 80/108\n",
            "  Progress: 100/108\n",
            "  IMPROVED: F1 0.701 -> 0.711 (+0.010)\n",
            "  Best params: {'learning_rate': 0.15, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 250, 'subsample': 0.8}\n",
            "  Time: 2150.2s\n",
            "\n",
            "Optimizing food...\n",
            "  Testing 108 parameter combinations...\n",
            "  Progress: 20/108\n",
            "  Progress: 40/108\n",
            "  Progress: 60/108\n",
            "  Progress: 80/108\n",
            "  Progress: 100/108\n",
            "  IMPROVED: F1 0.779 -> 0.782 (+0.004)\n",
            "  Best params: {'learning_rate': 0.2, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 250, 'subsample': 1.0}\n",
            "  Time: 2270.1s\n",
            "\n",
            "Optimizing shelter...\n",
            "  Testing 108 parameter combinations...\n",
            "  Progress: 20/108\n",
            "  Progress: 40/108\n",
            "  Progress: 60/108\n",
            "  Progress: 80/108\n",
            "  Progress: 100/108\n",
            "  No improvement found (current F1: 0.675)\n",
            "  Time: 2396.7s\n",
            "HYPERPARAMETER OPTIMIZATION SUMMARY\n",
            "  medical_help        : 0.505 -> 0.513 (IMPROVED)\n",
            "  search_and_rescue   : 0.365 -> 0.365 (No change)\n",
            "  water               : 0.701 -> 0.711 (IMPROVED)\n",
            "  food                : 0.779 -> 0.782 (IMPROVED)\n",
            "  shelter             : 0.675 -> 0.675 (No change)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Improved Models\n",
        "if improved_models:\n",
        "    # Create a copy of original models and update with improved ones\n",
        "    updated_models = label_models.copy()\n",
        "    updated_models.update(improved_models)\n",
        "\n",
        "    # Save updated models\n",
        "    updated_model_path = f'{model_dir}/optimized_xgboost_multilabel_v2.pkl'\n",
        "    joblib.dump(updated_models, updated_model_path)\n",
        "    print(f\"Saved updated models to: {updated_model_path}\")\n",
        "\n",
        "    # Save improvement results\n",
        "    import json\n",
        "    results_path = f'{model_dir}/optimization_results.json'\n",
        "    with open(results_path, 'w') as f:\n",
        "        # Convert numpy types to Python types for JSON serialization\n",
        "        results_to_save = []\n",
        "        for r in improvement_results:\n",
        "            results_to_save.append({\n",
        "                'category': r['category'],\n",
        "                'original_f1': float(r['original_f1']),\n",
        "                'new_f1': float(r['new_f1']),\n",
        "                'improvement': float(r['improvement']),\n",
        "                'best_params': r['best_params']\n",
        "            })\n",
        "        json.dump(results_to_save, f, indent=4)\n",
        "    print(f\"Saved optimization results to: {results_path}\")\n",
        "else:\n",
        "    print(\"No improved models to save.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0xHqx7OdWgI",
        "outputId": "c639d75a-fc3c-4fb7-844f-66b72ea93123"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved updated models to: /content/drive/MyDrive/AAI_Capstone/Models/optimized_xgboost_multilabel_v2.pkl\n",
            "Saved optimization results to: /content/drive/MyDrive/AAI_Capstone/Models/optimization_results.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Comparison Summary\n",
        "print(\"FINAL OPTIMIZATION SUMMARY\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "print(\"\\n1. BASELINE (Original XGBoost with default 0.5 threshold):\")\n",
        "print(f\"   F1 Micro: {baseline_f1_micro:.4f}\")\n",
        "print(f\"   F1 Macro: {baseline_f1_macro:.4f}\")\n",
        "\n",
        "print(\"\\n2. THRESHOLD-TUNED (Optimal thresholds per label):\")\n",
        "print(f\"   F1 Micro: {tuned_f1_micro:.4f} ({tuned_f1_micro - baseline_f1_micro:+.4f})\")\n",
        "print(f\"   F1 Macro: {tuned_f1_macro:.4f} ({tuned_f1_macro - baseline_f1_macro:+.4f})\")\n",
        "\n",
        "print(\"\\n3. CRITICAL CATEGORIES IMPROVEMENT:\")\n",
        "for result in improvement_results:\n",
        "    print(f\"   {result['category']:20s}: {result['original_f1']:.3f} -> {result['new_f1']:.3f} ({result['improvement']:+.3f})\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"FILES SAVED:\")\n",
        "print(f\"   - {model_dir}/optimal_thresholds.json\")\n",
        "if improved_models:\n",
        "    print(f\"   - {model_dir}/optimized_xgboost_multilabel_v2.pkl\")\n",
        "    print(f\"   - {model_dir}/optimization_results.json\")\n",
        "print(f\"{'='*70}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAXmzLEDQvLz",
        "outputId": "9ee66a4c-eef7-4992-c22f-67ebf9150205"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINAL OPTIMIZATION SUMMARY\n",
            "======================================================================\n",
            "\n",
            "1. BASELINE (Original XGBoost with default 0.5 threshold):\n",
            "   F1 Micro: 0.6246\n",
            "   F1 Macro: 0.4614\n",
            "\n",
            "2. THRESHOLD-TUNED (Optimal thresholds per label):\n",
            "   F1 Micro: 0.6817 (+0.0571)\n",
            "   F1 Macro: 0.4986 (+0.0372)\n",
            "\n",
            "3. CRITICAL CATEGORIES IMPROVEMENT:\n",
            "   medical_help        : 0.505 -> 0.513 (+0.008)\n",
            "   search_and_rescue   : 0.365 -> 0.365 (+0.000)\n",
            "   water               : 0.701 -> 0.711 (+0.010)\n",
            "   food                : 0.779 -> 0.782 (+0.004)\n",
            "   shelter             : 0.675 -> 0.675 (+0.000)\n",
            "\n",
            "======================================================================\n",
            "FILES SAVED:\n",
            "   - /content/drive/MyDrive/AAI_Capstone/Models/optimal_thresholds.json\n",
            "   - /content/drive/MyDrive/AAI_Capstone/Models/optimized_xgboost_multilabel_v2.pkl\n",
            "   - /content/drive/MyDrive/AAI_Capstone/Models/optimization_results.json\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NSaJtX41-h3f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
